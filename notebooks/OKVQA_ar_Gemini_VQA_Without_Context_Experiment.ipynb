{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lk6ceO1XERd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b223f142-3cd8-4ee5-aca3-9942932bd220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrjCxND2IamL"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sse1uQOmXF8z",
        "outputId": "1a7ac3f8-8007-4c69-a0ac-0b8474238127"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[range(0, 1010),\n",
              " range(1010, 2019),\n",
              " range(2019, 3028),\n",
              " range(3028, 4037),\n",
              " range(4037, 5046)]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "dataset_size , num_segments = 5046 , 5\n",
        "segment_size, remainder = divmod(dataset_size, num_segments)\n",
        "size_segments = [range(i * segment_size + min(i, remainder), (i + 1) * segment_size + min(i + 1, remainder)) for i in range(num_segments)]\n",
        "size_segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFnpb6aZxgzF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class GeminiConfig:\n",
        "  \"\"\"\n",
        "  Configuration for Gemini.\n",
        "  Contains default parameters that can be used globally.\n",
        "  \"\"\"\n",
        "\n",
        "  # General settings\n",
        "\n",
        "\n",
        "  # Model settings\n",
        "  MODEL_NAME = \"models/gemini-1.5-flash\"  #  Model name\n",
        "  # Generation settings\n",
        "  MAX_LENGTH = 20  # Maximum length of generated sequences\n",
        "\n",
        "  # Dataset settings vqav2-ar-validation-data\n",
        "  DATASET_PATH = \"ShahadMAlshalawi/okvqa-ar\"  # Path or name of the dataset\n",
        "  LANGUAGE = \"ar\"  # Language for questions/answers (\"ar\" for Arabic, \"en\" for English)\n",
        "  SPLIT = \"validation\"  # Dataset split to use (\"train\", \"validation\", \"test\")\n",
        "  SAVE_SEGMENT_DIR = \"/content/drive/MyDrive/ColabData/Gemini_VQA_Results/OKVQA-ar/VQA_generation_checkpoint\"  # Directory to save extracted answers\n",
        "\n",
        "  SIZE_SEGMENTS = [\n",
        "      range(0, 1010),\n",
        "      range(1010, 2019),\n",
        "      range(2019, 3028),\n",
        "      range(3028, 4037),\n",
        "      range(4037, 5046)\n",
        "      ]\n",
        "\n",
        "\n",
        "  CURRENT_INDEX_SEGMENT = 0  # Index of the current segment being processed\n",
        "  USERNAME = \"ShahadMAlshalawi\"  # Username for Hugging Face\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE74fPd0TIWr"
      },
      "source": [
        "# Gemini VQA Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rl7biewsTM1N"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from typing import List, Union, Iterable, Dict\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import base64\n",
        "from google.colab import userdata\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "class GeminiVQA:\n",
        "    \"\"\"\n",
        "    Implementation of Visual Question Answering using Gemini via the Google AI Gemini API.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str, model_name: str, max_tokens: int = 1024):\n",
        "        \"\"\"\n",
        "        Initializes the Gemini VQA model.\n",
        "\n",
        "        Args:\n",
        "            api_key (str): Google AI Gemini API key.\n",
        "            model_name (str): The name of the Gemini model to use.\n",
        "            max_tokens (int): The maximum number of tokens to generate in the answer.\n",
        "        \"\"\"\n",
        "        self.api_key = api_key\n",
        "        genai.configure(api_key=self.api_key)\n",
        "        self.model = genai.GenerativeModel(model_name)\n",
        "        self.model_name = model_name\n",
        "        self.max_tokens = max_tokens\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def _prepare_image(self, image: Union[str, np.ndarray, torch.Tensor, Image.Image]) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Prepares a single image for VQA, converting it to RGB format. Handles various input types.\n",
        "\n",
        "        Args:\n",
        "            image: The input image. Can be a file path, URL, NumPy array, PyTorch tensor, or PIL Image.\n",
        "\n",
        "        Returns:\n",
        "            A PIL Image object in RGB format.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If the input image type is unsupported or if an error occurs during image processing.\n",
        "            requests.exceptions.RequestException: If there's an error downloading the image from a URL.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            if isinstance(image, Image.Image):\n",
        "                return image.convert(\"RGB\")\n",
        "\n",
        "            elif isinstance(image, str):\n",
        "                if image.startswith(\"http\"):\n",
        "                    response = requests.get(image, stream=True)\n",
        "                    response.raise_for_status()\n",
        "                    return Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "                else:\n",
        "                    return Image.open(image).convert(\"RGB\")\n",
        "\n",
        "            elif isinstance(image, np.ndarray):\n",
        "                return Image.fromarray(image).convert(\"RGB\")\n",
        "\n",
        "            elif torch.is_tensor(image):\n",
        "                return Image.fromarray(image.permute(1, 2, 0).cpu().numpy().astype(np.uint8)).convert(\"RGB\")\n",
        "\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported image input type: {type(image)}\")\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            raise requests.exceptions.RequestException(f\"Error downloading image: {e}\")\n",
        "\n",
        "    def prepare_inputs(self, image: Union[str, np.ndarray, Image.Image], question: str):\n",
        "        \"\"\"\n",
        "        Prepares the image and question for the Gemini model, requesting the answer in Arabic.\n",
        "\n",
        "        Args:\n",
        "            image: The input image.\n",
        "            question (str): The question about the image.\n",
        "\n",
        "        Returns:\n",
        "            List: A list containing the prepared image and the question with an Arabic instruction.\n",
        "        \"\"\"\n",
        "        prepared_image = self._prepare_image(image)\n",
        "        # Updated prompt to be an AI assistant generating accurate answers in Arabic\n",
        "        # You are an AI assistant that generates accurate answer about image in Arabic.\\nQuestion:\n",
        "        prompt = f\"You are an AI assistant that generates accurate answer about image in Arabic.\\nQuestion: {question}\"\n",
        "        return [prepared_image, prompt]\n",
        "\n",
        "\n",
        "    def answer_question(self, image: Union[str, np.ndarray, Image.Image], question: str) -> str:\n",
        "        \"\"\"\n",
        "        Answers a question about an image using the Gemini API.\n",
        "\n",
        "        Args:\n",
        "            image: The input image.\n",
        "            question (str): The question about the image.\n",
        "\n",
        "        Returns:\n",
        "            str: The generated answer.\n",
        "        \"\"\"\n",
        "        prompt_parts = self.prepare_inputs(image, question)\n",
        "\n",
        "        try:\n",
        "            response = self.model.generate_content(prompt_parts, request_options={'timeout': 1200}, generation_config={\n",
        "                \"max_output_tokens\": self.max_tokens\n",
        "            })\n",
        "            return response.text\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating answer: {e}\")\n",
        "            return \"Error generating answer\"\n",
        "\n",
        "    def __call__(self, image: Union[str, np.ndarray, Image.Image], question: str) -> str:\n",
        "        \"\"\"\n",
        "        Answers a question about an image using the Gemini API.\n",
        "\n",
        "        Args:\n",
        "            image: The input image.\n",
        "            question (str): The question about the image.\n",
        "\n",
        "        Returns:\n",
        "            str: The generated answer.\n",
        "        \"\"\"\n",
        "        return self.answer_question(image, question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-kNbNFEK5mU"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_hrZM3kKiSw"
      },
      "outputs": [],
      "source": [
        "!pip install datasets --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc8ZN0wImZh0"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggmYy_0RLgCY"
      },
      "outputs": [],
      "source": [
        "# Login to Hugging Face\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "login(token=HF_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcM1d2qMmHau"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(GeminiConfig.DATASET_PATH,split=GeminiConfig.SPLIT)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fE1l-lRmiJc",
        "outputId": "0611e2c6-8500-4ecb-eec8-cbf76e58a08c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'metadata': {'image_id': 297147, 'question_id': 2971475, 'question_type': 'one', 'answer_type': 'other', 'confidence': 3}, 'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=640x480 at 0x799D36CE8E90>, 'question': {'en': 'What sport can you use this for?', 'ar': 'في أي رياضة يمكنك استخدام هذا؟'}, 'answers': {'en': ['race', 'race', 'race', 'race', 'race', 'race', 'motocross', 'motocross', 'ride', 'ride'], 'ar': ['سباق', 'سباق', 'سباق', 'سباق', 'سباق', 'سباق', 'موتوكروس', 'موتوكروس', 'يركب', 'يركب'], 'raw_en': ['racing', 'racing', 'racing', 'racing', 'racing', 'racing', 'motocross', 'motocross', 'riding', 'riding'], 'raw_ar': ['سباق', 'سباق', 'سباق', 'سباق', 'سباق', 'سباق', 'موتوكروس', 'موتوكروس', 'يركب', 'يركب'], 'confidence': ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes'], 'id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}}\n"
          ]
        }
      ],
      "source": [
        "print(dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RFXIs7eXPms"
      },
      "source": [
        "# Genearte Answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxSHC0rApP33"
      },
      "outputs": [],
      "source": [
        "api_key = userdata.get(\"GEMINI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "qQ3ntM0hXV6e",
        "outputId": "fbc10b53-59df-44d7-ee30-d78e29846659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: ما نوع السيارة التي تستعمل الشيء الظاهر في الصورة؟\n",
            "Answer: لا يمكن الإجابة على هذا السؤال بناءً على الصورة المقدمة. الصورة تعرض صنبور إطفاء حريق، ولا توجد أي سيارات ظاهرة فيه.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if api_key is None:\n",
        "    print(\"Error: GEMINI_API_KEY not found. Please set the GEMINI_API_KEY environment variable or pass the api key as a parameter to the constructor.\")\n",
        "else:\n",
        "    vqa_model = GeminiVQA(api_key=api_key, model_name=GeminiConfig.MODEL_NAME)\n",
        "\n",
        "    # Example usage with an image and question\n",
        "    # You can replace this with an image from your dataset or another source\n",
        "    image_url = \"/content/drive/MyDrive/Colab Notebooks/E1.png\"\n",
        "    question = \"ما نوع السيارة التي تستعمل الشيء الظاهر في الصورة؟\"\n",
        "\n",
        "    try:\n",
        "        answer = vqa_model(image_url, question)\n",
        "        print(f\"Question: {question}\")\n",
        "        print(f\"Answer: {answer}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BJ0dLajdkb8"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Assuming vqa_model is initialized in a previous cell\n",
        "# api_key = userdata.get(\"GEMINI_API_KEY\")\n",
        "# vqa_model = GeminiVQA(api_key=api_key, model_name=GeminiConfig.MODEL_NAME)\n",
        "\n",
        "# Process set of segments using loop\n",
        "for current_index_segment in range(0, 6):  # Loop through segments 0 to 30\n",
        "    print(f\"Processing segment {current_index_segment}...\")\n",
        "    rng = GeminiConfig.SIZE_SEGMENTS[current_index_segment]\n",
        "    data_segment = dataset.select(rng)\n",
        "\n",
        "    outputs = {\n",
        "        \"question_id\": [],\n",
        "        \"questions\": [],\n",
        "        \"image_id\": [],\n",
        "        \"answers\": [],\n",
        "        \"predictions\": []\n",
        "    }\n",
        "\n",
        "    for item in tqdm(data_segment, desc=f\"Generating answers for segment {current_index_segment}\"):\n",
        "        try:\n",
        "            question = item['question']['ar'] if GeminiConfig.LANGUAGE == 'ar' else item['question']['en']\n",
        "            ground_truth_answers = item['answers']['ar'] if GeminiConfig.LANGUAGE == 'ar' else item['answers']['en']\n",
        "            image = item['image']\n",
        "            question_id = str(item['metadata']['question_id'])\n",
        "            image_id = str(item['metadata']['image_id'])\n",
        "\n",
        "            prediction = vqa_model(image, question)\n",
        "\n",
        "            outputs[\"question_id\"].append(question_id)\n",
        "            outputs[\"questions\"].append(question) # Append the question here\n",
        "            outputs[\"image_id\"].append(image_id)\n",
        "            outputs[\"answers\"].append(ground_truth_answers)\n",
        "            outputs[\"predictions\"].append(prediction)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing item {item.get('metadata', {}).get('question_id', 'N/A')}: {e}\")\n",
        "            outputs[\"question_id\"].append(str(item.get('metadata', {}).get('question_id', 'N/A')))\n",
        "            outputs[\"questions\"].append(\"N/A\") # Append N/A for question if error\n",
        "            outputs[\"image_id\"].append(str(item.get('metadata', {}).get('image_id', 'N/A')))\n",
        "            outputs[\"answers\"].append([])  # Append empty list for ground truth if error\n",
        "            outputs[\"predictions\"].append(\"Error generating answer\") # Indicate error in prediction\n",
        "\n",
        "\n",
        "    #saving the predictions to a JSON file\n",
        "    save_path = f\"{GeminiConfig.SAVE_SEGMENT_DIR}/segment_{current_index_segment}_outputs.json\"\n",
        "    with open(save_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(outputs, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"Outputs saved to {save_path}\")\n",
        "    # Optionally display a sample of the outputs\n",
        "    # display(pd.DataFrame.from_dict(outputs).head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAtE6lofViXd"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-RLxayoAJtp"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFrSQ8GTAJtq"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evNU1EL4AJtq"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/shahadMAlshalawi/Modular-Arabic-VQA.git --no-warn-conflicts --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee-riJnbAJtr"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import textwrap\n",
        "import tqdm\n",
        "from PIL import Image\n",
        "import requests\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "import evaluate\n",
        "import json\n",
        "import datasets\n",
        "import aravqa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gkLCFM3WIn0"
      },
      "source": [
        "### Loading the data from drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gc9fdciF_-qA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Directory containing the saved JSON output files\n",
        "output_dir = GeminiConfig.SAVE_SEGMENT_DIR\n",
        "\n",
        "# Initialize a dictionary to store the combined outputs with the correct keys\n",
        "outputs = {\n",
        "    \"question_id\": [],\n",
        "    \"questions\": [],\n",
        "    \"image_id\": [],\n",
        "    \"answers\": [],\n",
        "    \"predictions\": []\n",
        "}\n",
        "\n",
        "# Iterate through the files in the directory and load the JSON data\n",
        "for filename in sorted(os.listdir(output_dir)):\n",
        "    if filename.endswith('.json'):\n",
        "        file_path = os.path.join(output_dir, filename)\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "            # Append the data from each file to the combined outputs dictionary\n",
        "            for key in outputs.keys():\n",
        "                if key in data:  # Check if the key exists in the loaded data\n",
        "                    outputs[key].extend(data[key])\n",
        "                else:\n",
        "                    # This case should not happen with the corrected keys, but good practice to handle\n",
        "                    print(f\"Warning: Key '{key}' not found in file '{filename}'. Skipping.\")\n",
        "\n",
        "\n",
        "# Display the first few entries of the combined outputs for verification\n",
        "print(\"Combined outputs loaded successfully. First 5 entries:\")\n",
        "print(outputs['predictions'][:5])\n",
        "print(outputs['questions'][:5])\n",
        "print(outputs['answers'][:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7-f7_s2qr0t"
      },
      "outputs": [],
      "source": [
        "# Print the last 5 entries of the combined outputs for verification\n",
        "print(\"Combined outputs loaded successfully. Last 5 entries:\")\n",
        "print(outputs['predictions'][-2:])\n",
        "print(outputs['questions'][-2:])\n",
        "print(outputs['answers'][-2:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWjb8f5o_U8z"
      },
      "source": [
        "## Evaluate in segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9NKb7nnAJts"
      },
      "outputs": [],
      "source": [
        "from aravqa.modules.evaluation import BLEUEvaluator\n",
        "from aravqa.modules.evaluation import BERTScoreEvaluator\n",
        "from aravqa.modules.evaluation import FuzzEvaluator\n",
        "import os\n",
        "\n",
        "# Define the directory to save segmented results\n",
        "segmented_results_dir = f\"/content/drive/MyDrive/ColabData/Gemini_VQA_Results/VQAv2-ar/Evaluation_Results/\"\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('GPT_API_KEY')\n",
        "\n",
        "# Initialize evaluators\n",
        "bleu_evaluator = BLEUEvaluator(max_order=1)\n",
        "BertScore_evaluator = BERTScoreEvaluator()\n",
        "fuzzy_evaluator = FuzzEvaluator(OPENAI_API_KEY)\n",
        "\n",
        "\n",
        "# Iterate through segments starting from segment 56\n",
        "for i, rng in enumerate(GeminiConfig.SIZE_SEGMENTS[1:], start=1):\n",
        "    print(f\"Evaluating segment {i}...\")\n",
        "\n",
        "    # Select the data for the current segment\n",
        "    segment_outputs = {\n",
        "        \"question_id\": outputs[\"question_id\"][rng.start:rng.stop],\n",
        "        \"questions\": outputs[\"questions\"][rng.start:rng.stop],\n",
        "        \"image_id\": outputs[\"image_id\"][rng.start:rng.stop],\n",
        "        \"answers\": outputs[\"answers\"][rng.start:rng.stop],\n",
        "        \"predictions\": outputs[\"predictions\"][rng.start:rng.stop]\n",
        "    }\n",
        "\n",
        "    # Perform evaluations for the current segment\n",
        "    bleu_results = bleu_evaluator.evaluate(predictions=segment_outputs['predictions'],\n",
        "                                           references=segment_outputs['answers']\n",
        "                                           )\n",
        "\n",
        "    bertScore_results = BertScore_evaluator.evaluate(predictions=segment_outputs['predictions'],\n",
        "                                                   references=segment_outputs['answers']\n",
        "                                                   )\n",
        "\n",
        "    fuzzy_results = fuzzy_evaluator.evaluate(predictions=segment_outputs['predictions'],\n",
        "                                           references=segment_outputs['answers'],\n",
        "                                             questions=segment_outputs['questions']\n",
        "                                           )\n",
        "\n",
        "    # Prepare segment results dictionary\n",
        "    segment_eval_results = {\n",
        "        'question_id': segment_outputs['question_id'],\n",
        "        'questions': segment_outputs['questions'],\n",
        "        'image_id': segment_outputs['image_id'],\n",
        "        'answers': segment_outputs['answers'],\n",
        "        'predictions': segment_outputs['predictions'],\n",
        "        'bleu': bleu_results['bleu'],\n",
        "        'f1_bertscore': bertScore_results['f1_bertscore'],\n",
        "        'fuzz_accuracy': fuzzy_results['fuzz_accuracy'],\n",
        "    }\n",
        "\n",
        "    # Add overall metrics to the first row of the segment results\n",
        "    if len(segment_outputs['question_id']) > 0:\n",
        "        segment_eval_results['overall_bleu'] = [bleu_results['overall_bleu']] + [None] * (len(segment_outputs['question_id']) - 1)\n",
        "        segment_eval_results['overall_f1_bertscore'] = [bertScore_results['overall_f1_bertscore']] + [None] * (len(segment_outputs['question_id']) - 1)\n",
        "        segment_eval_results['fuzz_overall_accuracy'] = [fuzzy_results['fuzz_overall_accuracy']] + [None] * (len(segment_outputs['question_id']) - 1)\n",
        "    else:\n",
        "        segment_eval_results['overall_bleu'] = []\n",
        "        segment_eval_results['overall_f1_bertscore'] = []\n",
        "        segment_eval_results['fuzz_overall_accuracy'] = []\n",
        "\n",
        "\n",
        "    # Create a DataFrame and save the segment results to a CSV file\n",
        "    segment_df = pd.DataFrame.from_dict(segment_eval_results)\n",
        "    segment_filename = f\"segment_{i}_results.csv\"\n",
        "    segment_file_path = os.path.join(segmented_results_dir, segment_filename)\n",
        "    segment_df.to_csv(segment_file_path, index=False)\n",
        "\n",
        "    print(f\"Segment {i} results saved to {segment_file_path}\")\n",
        "\n",
        "print(\"\\nEvaluation of all segments completed.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}